import os
import json
import psycopg2
import pandas as pd
import numpy as np
from datetime import datetime

# === LOCALIZA√á√ÉO DIN√ÇMICA DO db_config.json ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "db_config.json")

with open(CONFIG_PATH, "r", encoding="utf-8") as f:
    DB_CONFIG = json.load(f)

# === CONEX√ÉO COM O POSTGRESQL ===
conn = psycopg2.connect(**DB_CONFIG)
cur = conn.cursor()

# === FUN√á√ÉO: CONVERTER TIPOS NUMPY PARA PYTHON NATIVOS ===
def converter_tipos_numpy(valor):
    """
    Converte tipos numpy para tipos Python nativos compat√≠veis com psycopg2
    """
    if pd.isna(valor):
        return None
    elif isinstance(valor, np.integer):  # Inclui int64, int32, int16, int8
        return int(valor)
    elif isinstance(valor, np.floating):  # Inclui float64, float32
        return float(valor)
    elif isinstance(valor, (np.bool_, bool)):  # Apenas np.bool_
        return bool(valor)
    elif isinstance(valor, np.str_):  # String numpy (np.unicode_ removido no NumPy 2.0)
        return str(valor)
    elif isinstance(valor, pd.Timestamp):
        return valor.to_pydatetime()
    elif isinstance(valor, np.datetime64):
        return pd.Timestamp(valor).to_pydatetime()
    elif hasattr(valor, 'item'):  # Qualquer escalar numpy
        return valor.item()
    else:
        return valor

# === FUN√á√ÉO: LIMPAR DATAFRAME DE TIPOS NUMPY ===
def limpar_tipos_numpy(df):
    """
    Remove tipos numpy do DataFrame para evitar erros de inser√ß√£o no PostgreSQL
    """
    df_limpo = df.copy()
    
    for coluna in df_limpo.columns:
        dtype_str = str(df_limpo[coluna].dtype)
        
        if df_limpo[coluna].dtype == 'object':
            # Para colunas object, aplicar convers√£o em cada valor
            df_limpo[coluna] = df_limpo[coluna].apply(converter_tipos_numpy)
        elif 'int' in dtype_str:
            # Converter qualquer tipo inteiro para int Python nativo
            df_limpo[coluna] = df_limpo[coluna].apply(lambda x: int(x) if pd.notna(x) else None)
        elif 'float' in dtype_str:
            # Converter qualquer tipo float para float Python nativo
            df_limpo[coluna] = df_limpo[coluna].apply(lambda x: float(x) if pd.notna(x) else None)
        elif 'bool' in dtype_str:
            # Converter bool numpy para bool Python
            df_limpo[coluna] = df_limpo[coluna].apply(lambda x: bool(x) if pd.notna(x) else None)
        elif 'datetime' in dtype_str:
            # Converter timestamps para datetime Python
            df_limpo[coluna] = df_limpo[coluna].apply(
                lambda x: x.to_pydatetime() if pd.notna(x) and hasattr(x, 'to_pydatetime') else x
            )
    
    return df_limpo

# === FUN√á√ÉO: CRIAR TABELA DE LOG ===
def criar_tabela_log():
    """
    Cria tabela para armazenar logs de extra√ß√£o e valida√ß√£o
    """
    cur.execute("""
    CREATE TABLE IF NOT EXISTS log_extractions (
        id SERIAL PRIMARY KEY,
        data_execucao TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        tabela VARCHAR(50),
        acao VARCHAR(20), -- 'VALIDACAO', 'EXTRACAO', 'ERRO'
        registros_processados INT DEFAULT 0,
        duplicatas_encontradas INT DEFAULT 0,
        nulos_encontrados INT DEFAULT 0,
        duplicatas_removidas INT DEFAULT 0,
        nulos_tratados INT DEFAULT 0,
        status VARCHAR(10), -- 'SUCESSO', 'ERRO', 'AVISO'
        detalhes TEXT,
        arquivo_gerado VARCHAR(255)
    );
    """)
    conn.commit()
    print("üìã Tabela de log criada/verificada: log_extractions")

# === FUN√á√ÉO: INSERIR LOG (COM TRATAMENTO DE TIPOS) ===
def inserir_log(tabela, acao, registros=0, duplicatas=0, nulos=0, dup_removidas=0, nulos_tratados=0, status='SUCESSO', detalhes='', arquivo=''):
    """
    Insere registro na tabela de log com convers√£o de tipos
    """
    # Converter todos os valores para tipos Python nativos
    params = (
        str(tabela),
        str(acao),
        int(registros) if registros is not None else 0,
        int(duplicatas) if duplicatas is not None else 0,
        int(nulos) if nulos is not None else 0,
        int(dup_removidas) if dup_removidas is not None else 0,
        int(nulos_tratados) if nulos_tratados is not None else 0,
        str(status),
        str(detalhes),
        str(arquivo)
    )
    
    cur.execute("""
        INSERT INTO log_extractions 
        (tabela, acao, registros_processados, duplicatas_encontradas, nulos_encontrados, 
         duplicatas_removidas, nulos_tratados, status, detalhes, arquivo_gerado)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """, params)
    conn.commit()

# === FUN√á√ÉO: VALIDAR E LIMPAR DADOS ===
def validar_e_limpar_dados(df, tabela_nome):
    """
    Valida dados, remove duplicatas e trata valores nulos
    Retorna DataFrame limpo e estat√≠sticas
    """
    print(f"  üîç Validando dados da tabela {tabela_nome}...")
    
    # Estat√≠sticas iniciais
    registros_iniciais = len(df)
    duplicatas_iniciais = df.duplicated().sum()
    
    # Contar nulos por coluna (exceto ID que pode ser auto-incremento)
    colunas_importantes = [col for col in df.columns if col.lower() not in ['id']]
    nulos_por_coluna = df[colunas_importantes].isnull().sum()
    nulos_totais = nulos_por_coluna.sum()
    
    print(f"    üìä Registros iniciais: {registros_iniciais}")
    print(f"    üîÑ Duplicatas encontradas: {duplicatas_iniciais}")
    print(f"    ‚ùå Valores nulos encontrados: {nulos_totais}")
    
    # === TRATAMENTO DE DUPLICATAS ===
    df_limpo = df.copy()
    
    if duplicatas_iniciais > 0:
        # Remove duplicatas mantendo o primeiro registro
        df_limpo = df_limpo.drop_duplicates()
        duplicatas_removidas = registros_iniciais - len(df_limpo)
        print(f"    ‚úÖ {duplicatas_removidas} duplicatas removidas")
        
        inserir_log(
            tabela=tabela_nome,
            acao='VALIDACAO',
            registros=registros_iniciais,
            duplicatas=duplicatas_iniciais,
            dup_removidas=duplicatas_removidas,
            status='AVISO' if duplicatas_iniciais > 0 else 'SUCESSO',
            detalhes=f'Duplicatas encontradas e removidas: {duplicatas_removidas}'
        )
    
    # === TRATAMENTO DE VALORES NULOS ===
    nulos_tratados = 0
    
    if nulos_totais > 0:
        print(f"    üîß Tratando valores nulos:")
        
        for coluna in colunas_importantes:
            nulos_coluna = df_limpo[coluna].isnull().sum()
            if nulos_coluna > 0:
                print(f"      ‚Ä¢ {coluna}: {nulos_coluna} nulos", end=" ‚Üí ")
                
                # Estrat√©gias espec√≠ficas por tipo de coluna
                if df_limpo[coluna].dtype == 'object':  # Texto
                    if 'nome' in coluna.lower() or 'cliente' in coluna.lower() or 'advogado' in coluna.lower() or 'juiz' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('Nome n√£o informado')
                    elif 'cpf' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('000.000.000-00')
                    elif 'endereco' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('Endere√ßo n√£o informado')
                    elif 'cidade' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('Cidade n√£o informada')
                    elif 'estado' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('XX')
                    elif 'oab' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('OAB n√£o informada')
                    elif 'vara' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna('Vara n√£o informada')
                    elif 'numero' in coluna.lower() and 'processo' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna(f'PROC-{datetime.now().strftime("%Y%m%d")}-{len(df_limpo)}')
                    else:
                        df_limpo[coluna] = df_limpo[coluna].fillna('N√£o informado')
                    print("preenchido com valor padr√£o")
                    
                elif df_limpo[coluna].dtype in ['int64', 'float64', 'Int64', 'Float64']:  # N√∫meros
                    if 'valor' in coluna.lower():
                        df_limpo[coluna] = df_limpo[coluna].fillna(0.0)
                        print("preenchido com 0.0")
                    else:
                        df_limpo[coluna] = df_limpo[coluna].fillna(0)
                        print("preenchido com 0")
                        
                elif 'bool' in str(df_limpo[coluna].dtype):  # Booleano
                    df_limpo[coluna] = df_limpo[coluna].fillna(False)
                    print("preenchido com False")
                    
                elif 'date' in str(df_limpo[coluna].dtype):  # Data
                    df_limpo[coluna] = df_limpo[coluna].fillna(pd.Timestamp('1900-01-01'))
                    print("preenchido com data padr√£o")
                
                nulos_tratados += nulos_coluna
        
        print(f"    ‚úÖ {nulos_tratados} valores nulos tratados")
        
        inserir_log(
            tabela=tabela_nome,
            acao='VALIDACAO',
            registros=len(df_limpo),
            nulos=nulos_totais,
            nulos_tratados=nulos_tratados,
            status='AVISO' if nulos_totais > 0 else 'SUCESSO',
            detalhes=f'Valores nulos encontrados e tratados: {nulos_tratados}'
        )
    
    # === VALIDA√á√ïES ESPEC√çFICAS POR TABELA ===
    if tabela_nome == 'fato_processos':
        # Garantir que n√£o h√° processos sem pessoa, juiz ou advogado
        registros_invalidos = df_limpo[
            (df_limpo['id_pessoa'].isnull()) | 
            (df_limpo['id_juiz'].isnull()) | 
            (df_limpo['id_advogado'].isnull())
        ]
        
        if len(registros_invalidos) > 0:
            df_limpo = df_limpo.dropna(subset=['id_pessoa', 'id_juiz', 'id_advogado'])
            print(f"    ‚ö†Ô∏è {len(registros_invalidos)} processos inv√°lidos removidos (sem pessoa/juiz/advogado)")
    
    # === CONVERTER TIPOS NUMPY PARA PYTHON NATIVOS ===
    print(f"  üîß Convertendo tipos numpy para tipos Python nativos...")
    df_limpo = limpar_tipos_numpy(df_limpo)
    print(f"    ‚úÖ Tipos convertidos com sucesso")
    
    # Estat√≠sticas finais
    registros_finais = len(df_limpo)
    print(f"    ‚úÖ Registros finais ap√≥s limpeza: {registros_finais}")
    print(f"    üìà Dados limpos: {((registros_finais/registros_iniciais)*100):.1f}% dos registros originais")
    
    return df_limpo, {
        'registros_iniciais': registros_iniciais,
        'registros_finais': registros_finais,
        'duplicatas_encontradas': duplicatas_iniciais,
        'duplicatas_removidas': duplicatas_iniciais,
        'nulos_encontrados': nulos_totais,
        'nulos_tratados': nulos_tratados
    }

# === FUN√á√ÉO: EXTRA√á√ÉO PARA CSV COM VALIDA√á√ÉO ===
def extrair_csvs_validados():
    """
    Extrai todas as tabelas para CSV com valida√ß√£o completa
    """
    print("üìÑ Iniciando extra√ß√£o validada dos CSVs...")
    
    # Cria pasta para os CSVs se n√£o existir
    csv_dir = os.path.join(BASE_DIR, "csvs")
    os.makedirs(csv_dir, exist_ok=True)
    
    # Lista das tabelas para exportar
    tabelas = ['dim_pessoa', 'dim_juiz', 'dim_advogado', 'fato_processos']
    
    resultados_gerais = {
        'total_tabelas': len(tabelas),
        'tabelas_sucesso': 0,
        'total_registros_originais': 0,
        'total_registros_finais': 0,
        'total_duplicatas_removidas': 0,
        'total_nulos_tratados': 0,
        'arquivos_gerados': []
    }
    
    for tabela in tabelas:
        try:
            print(f"\nüìã Processando tabela: {tabela}")
            print("-" * 50)
            
            # 1. EXTRA√á√ÉO DOS DADOS
            print(f"  üì• Extraindo dados da tabela {tabela}...")
            df_original = pd.read_sql(f"SELECT * FROM {tabela}", conn)
            print(f"    ‚úÖ {len(df_original)} registros extra√≠dos")
            
            # 2. VALIDA√á√ÉO E LIMPEZA
            df_limpo, stats = validar_e_limpar_dados(df_original, tabela)
            
            # 3. VERIFICA√á√ÉO FINAL DE INTEGRIDADE
            print(f"  üîê Verifica√ß√£o final de integridade...")
            
            # Verificar se ainda h√° duplicatas
            duplicatas_finais = df_limpo.duplicated().sum()
            if duplicatas_finais > 0:
                print(f"    ‚ö†Ô∏è ATEN√á√ÉO: {duplicatas_finais} duplicatas ainda presentes!")
                df_limpo = df_limpo.drop_duplicates()
            
            # Verificar nulos em colunas cr√≠ticas
            colunas_criticas = [col for col in df_limpo.columns if col.lower() not in ['id']]
            nulos_finais = df_limpo[colunas_criticas].isnull().sum().sum()
            
            print(f"    ‚úÖ Duplicatas finais: {duplicatas_finais}")
            print(f"    ‚úÖ Nulos finais em colunas cr√≠ticas: {nulos_finais}")
            
            # 4. SALVAR CSV
            csv_path = os.path.join(csv_dir, f"{tabela}.csv")
            df_limpo.to_csv(csv_path, index=False, encoding='utf-8')
            
            # Calcular tamanho do arquivo
            tamanho_mb = os.path.getsize(csv_path) / (1024 * 1024)
            
            print(f"  üíæ Arquivo salvo: {tabela}.csv ({len(df_limpo)} registros, {tamanho_mb:.2f} MB)")
            
            # 5. LOG DA EXTRA√á√ÉO
            inserir_log(
                tabela=tabela,
                acao='EXTRACAO',
                registros=len(df_limpo),
                duplicatas=stats['duplicatas_encontradas'],
                nulos=stats['nulos_encontrados'],
                dup_removidas=stats['duplicatas_removidas'],
                nulos_tratados=stats['nulos_tratados'],
                status='SUCESSO',
                detalhes=f'Arquivo CSV gerado com {len(df_limpo)} registros v√°lidos',
                arquivo=f"{tabela}.csv"
            )
            
            # Atualizar estat√≠sticas gerais
            resultados_gerais['tabelas_sucesso'] += 1
            resultados_gerais['total_registros_originais'] += stats['registros_iniciais']
            resultados_gerais['total_registros_finais'] += stats['registros_finais']
            resultados_gerais['total_duplicatas_removidas'] += stats['duplicatas_removidas']
            resultados_gerais['total_nulos_tratados'] += stats['nulos_tratados']
            resultados_gerais['arquivos_gerados'].append({
                'tabela': tabela,
                'arquivo': f"{tabela}.csv",
                'registros': len(df_limpo),
                'tamanho_mb': round(tamanho_mb, 2)
            })
            
        except Exception as e:
            print(f"  ‚ùå ERRO ao processar {tabela}: {e}")
            inserir_log(
                tabela=tabela,
                acao='ERRO',
                status='ERRO',
                detalhes=f'Erro na extra√ß√£o: {str(e)}'
            )
    
    return resultados_gerais

# === FUN√á√ÉO: GERAR RELAT√ìRIO DE LOGS ===
def gerar_relatorio_logs():
    """
    Gera relat√≥rio consolidado dos logs
    """
    print(f"\nüìä Gerando relat√≥rio de logs...")
    
    # Buscar logs da execu√ß√£o atual (√∫ltimos 5 minutos)
    cur.execute("""
        SELECT * FROM log_extractions 
        WHERE data_execucao >= NOW() - INTERVAL '5 minutes'
        ORDER BY data_execucao DESC
    """)
    
    logs = cur.fetchall()
    colunas = [desc[0] for desc in cur.description]
    
    if logs:
        df_logs = pd.DataFrame(logs, columns=colunas)
        
        # Limpar tipos numpy do DataFrame de logs tamb√©m
        df_logs = limpar_tipos_numpy(df_logs)
        
        # Salvar relat√≥rio de logs
        log_path = os.path.join(BASE_DIR, "csvs", "relatorio_logs.csv")
        df_logs.to_csv(log_path, index=False, encoding='utf-8')
        
        print(f"  ‚úÖ Relat√≥rio de logs salvo: relatorio_logs.csv")
        return True
    
    return False

# === EXECU√á√ÉO PRINCIPAL ===
def main():
    try:
        print("üöÄ Iniciando extra√ß√£o validada da base jur√≠dica...")
        print("=" * 70)
        
        # 1. Criar tabela de log
        criar_tabela_log()
        
        # 2. Log de in√≠cio da execu√ß√£o
        inserir_log(
            tabela='SISTEMA',
            acao='INICIO',
            status='SUCESSO',
            detalhes='Iniciando processo de extra√ß√£o validada'
        )
        
        # 3. Extrair CSVs com valida√ß√£o
        resultados = extrair_csvs_validados()
        
        # 4. Mostrar estat√≠sticas da extra√ß√£o
        print(f"\nüìà ESTAT√çSTICAS DA BASE:")
        print("=" * 70)
        
        # Estat√≠sticas do banco
        cur.execute("SELECT COUNT(*) FROM dim_pessoa")
        total_pessoas = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM dim_juiz")
        total_juizes = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM dim_advogado")
        total_advogados = cur.fetchone()[0]
        cur.execute("SELECT COUNT(*) FROM fato_processos")
        total_processos = cur.fetchone()[0]
        
        print(f"   üìä Dados no Banco:")
        print(f"     ‚Ä¢ Pessoas: {total_pessoas:,}")
        print(f"     ‚Ä¢ Ju√≠zes: {total_juizes:,}")
        print(f"     ‚Ä¢ Advogados: {total_advogados:,}")
        print(f"     ‚Ä¢ Processos: {total_processos:,}")
        
        # 5. Estat√≠sticas da extra√ß√£o
        print(f"\n   üîç Resultados da Valida√ß√£o:")
        print(f"     ‚Ä¢ Tabelas processadas: {resultados['tabelas_sucesso']}/{resultados['total_tabelas']}")
        print(f"     ‚Ä¢ Registros originais: {resultados['total_registros_originais']:,}")
        print(f"     ‚Ä¢ Registros finais: {resultados['total_registros_finais']:,}")
        print(f"     ‚Ä¢ Duplicatas removidas: {resultados['total_duplicatas_removidas']:,}")
        print(f"     ‚Ä¢ Valores nulos tratados: {resultados['total_nulos_tratados']:,}")
        
        # 6. Arquivos gerados
        print(f"\n   üìÅ Arquivos CSV Gerados:")
        for arquivo in resultados['arquivos_gerados']:
            print(f"     ‚Ä¢ {arquivo['arquivo']}: {arquivo['registros']:,} registros ({arquivo['tamanho_mb']} MB)")
        
        # 7. Gerar relat√≥rio de logs
        gerar_relatorio_logs()
        
        # 8. Log de fim da execu√ß√£o
        taxa_sucesso = (resultados['tabelas_sucesso'] / resultados['total_tabelas']) * 100
        inserir_log(
            tabela='SISTEMA',
            acao='FIM',
            registros=resultados['total_registros_finais'],
            duplicatas=resultados['total_duplicatas_removidas'],
            nulos_tratados=resultados['total_nulos_tratados'],
            status='SUCESSO' if taxa_sucesso == 100 else 'AVISO',
            detalhes=f'Extra√ß√£o conclu√≠da: {taxa_sucesso:.1f}% de sucesso'
        )
        
        print(f"\nüéØ EXTRA√á√ÉO VALIDADA COMPLETA:")
        print("=" * 70)
        print(f"   ‚úÖ CSVs extra√≠dos com valida√ß√£o completa")
        print(f"   ‚úÖ Garantia: 0 duplicatas, 0 valores nulos cr√≠ticos")
        print(f"   ‚úÖ Tipos numpy convertidos para compatibilidade PostgreSQL")
        print(f"   ‚úÖ Logs salvos na tabela 'log_extractions'")
        print(f"   üìÅ Arquivos dispon√≠veis em: {os.path.join(BASE_DIR, 'csvs')}")
        print(f"   üìä Taxa de sucesso: {taxa_sucesso:.1f}%")
            
    except Exception as e:
        print(f"‚ùå Erro cr√≠tico na execu√ß√£o: {e}")
        inserir_log(
            tabela='SISTEMA',
            acao='ERRO',
            status='ERRO',
            detalhes=f'Erro cr√≠tico: {str(e)}'
        )
        
    finally:
        cur.close()
        conn.close()
        print("\nüîå Conex√£o com banco encerrada.")

if __name__ == "__main__":
    main()